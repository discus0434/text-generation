{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import tweepy\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "@dataclass\n",
    "class AuthenticationInfo:\n",
    "    api_key: str = \"\",\n",
    "    api_secret_key: str = \"\",\n",
    "    bearer_token: str = \"\",\n",
    "    access_token: str = \"\",\n",
    "    access_token_secret: str = \"\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune(\n",
    "    src_dir: str = \"sample_texts\", \n",
    "    dst_file: str = \"finetune\", \n",
    "    run_name: str = \"gpt2ja-finetune-small\"\n",
    ") -> None:\n",
    "    \n",
    "    # Encode a dataset\n",
    "    subprocess.run(\n",
    "        f\"python gpt2-japanese/encode_bpe.py --src_dir {src_dir} --dst_file {dst_file}\",\n",
    "        shell=True,\n",
    "    )\n",
    "    \n",
    "    # Fine-Tune\n",
    "    subprocess.run(\n",
    "        f\"python gpt2-japanese/run_finetune.py \\\n",
    "            --base_model gpt2ja-small \\\n",
    "            --dataset {dst_file}.npz \\\n",
    "            --run_name {run_name}\",\n",
    "        shell=True,\n",
    "    )\n",
    "    \n",
    "    # Remove interim files\n",
    "    subprocess.run(f\"rm {dst_file}.npz\", shell=True)\n",
    "    subprocess.run(\"for i in `seq 0 7`; do rm tmp$i.pkl; done\", shell=True)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(\n",
    "    model: str = \"checkpoints/gpt2ja-finetune-small\",\n",
    "    num_generate: int = 1,\n",
    "    temperature: float = 1.0,\n",
    "    min_length: int = 120,\n",
    "    max_length: int = 130,\n",
    "    output_file: str = \"dist/dist.txt\",\n",
    "    context: str = \"<|endoftext|>\",\n",
    ") -> str: \n",
    "        \n",
    "    generated = subprocess.run(\n",
    "        f\"TF_CPP_MIN_LOG_LEVEL=3 \\\n",
    "            python gpt2-japanese/gpt2-generate.py \\\n",
    "            --model {model} \\\n",
    "            --num_generate {num_generate} \\\n",
    "            --temperature {temperature} \\\n",
    "            --min_length {min_length} \\\n",
    "            --max_length {max_length} \\\n",
    "            --output_file {output_file} \\\n",
    "            --context={context}\",\n",
    "        shell=True,\n",
    "        capture_output=True,\n",
    "    )\n",
    "    \n",
    "    return generated.stdout.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_tweet(\n",
    "    client: tweepy.Client,\n",
    "    text: str,\n",
    "    score: str,\n",
    "    model: str,\n",
    ") -> None:\n",
    "    json = {}\n",
    "    \n",
    "    poll_or_not = random.randint(0, 100)\n",
    "    if poll_or_not >= 90:\n",
    "        options = []\n",
    "        for _ in range(3):\n",
    "            options.append(\n",
    "                generate(\n",
    "                    model=model, \n",
    "                    context=text,\n",
    "                    num_generate=1, \n",
    "                    output_file=\"dist/dist.txt\", \n",
    "                    min_length=5, \n",
    "                    max_length=24,\n",
    "                )\n",
    "            )\n",
    "        json[\"poll\"] = {\"options\": options, \"duration_minutes\": 30}\n",
    "        \n",
    "    json[\"text\"] = text + f\"\\n score: {score}\"\n",
    "    \n",
    "    return client._make_request(\"POST\", \"/2/tweets\", json=json, user_auth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_tweets(\n",
    "    auth_info: AuthenticationInfo\n",
    ") -> None:\n",
    "\n",
    "    client = tweepy.Client(\n",
    "        consumer_key=auth_info.api_key,\n",
    "        consumer_secret=auth_info.api_secret_key,\n",
    "        access_token=auth_info.access_token,\n",
    "        access_token_secret=auth_info.access_token_secret,\n",
    "    )\n",
    "    \n",
    "    today = datetime.strftime(datetime.today(), '%Y-%m-%d')\n",
    "    \n",
    "    # If a fine-tuned GPT-2-ja-small does not exist, make it\n",
    "    if not len(glob.glob(\"./checkpoints/*small\")):\n",
    "\n",
    "        # Remove any other checkpoint if exists\n",
    "        if os.path.exists(\"./checkpoints\"):\n",
    "            subprocess.run(\n",
    "                \"for i in `ls checkpoints | cut -d ' ' -f1`; \\\n",
    "                do rm -rf checkpoints/$i; done\",\n",
    "                shell=True,\n",
    "            )  \n",
    "        \n",
    "        # Do fine-tuning\n",
    "        finetune(\n",
    "            dst_file=f\"{today}-finetune\",\n",
    "            run_name=f\"gpt2ja-{today}-finetune-small\",\n",
    "        )\n",
    "    \n",
    "    model = glob.glob(\"./checkpoints/*small\")[0]\n",
    "        \n",
    "    generated_text = generate(\n",
    "        model=model,\n",
    "        context=\"\",\n",
    "        num_generate=1,\n",
    "        output_file=\"dist/dist.txt\",\n",
    "    )\n",
    "    \n",
    "    score = (\n",
    "        subprocess.run(\n",
    "            f\"python gpt2-japanese/gpt2-score.py \\\n",
    "                dist/dist.txt \\\n",
    "                --model {model} \\\n",
    "                --exclude-end\",\n",
    "            shell=True,\n",
    "            capture_output=True,\n",
    "        )\n",
    "        .stdout\n",
    "        .decode()\n",
    "        .split(\"\\t\")[-1]\n",
    "        .strip()\n",
    "    )\n",
    "    \n",
    "    post_tweet(client, text=generated_text, score=score, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_info = AuthenticationInfo(\n",
    "    api_key=os.getenv(\"TEINEI_API_KEY\"),\n",
    "    api_secret_key=os.getenv(\"TEINEI_API_SECRET_KEY\"),\n",
    "    access_token=os.getenv(\"TEINEI_ACCESS_TOKEN\"),\n",
    "    access_token_secret=os.getenv(\"TEINEI_ACCESS_TOKEN_SECRET\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-60.879\n"
     ]
    }
   ],
   "source": [
    "create_custom_tweets(auth_info=auth_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('textgen')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80cfaf54ddc48834aebaa66aa95b4002d516e0c3f63b9bd458051d5ed5e0fa4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
