{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Performance Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import glob\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import tweepy\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from scripts.config import NG_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataclass for Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AuthenticationInfo:\n",
    "    api_key: str = \"\",\n",
    "    api_secret_key: str = \"\",\n",
    "    bearer_token: str = \"\",\n",
    "    access_token: str = \"\",\n",
    "    access_token_secret: str = \"\","
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune(\n",
    "    src_dir: str = \"sample_texts\", \n",
    "    dst_file: str = \"finetune\", \n",
    "    run_name: str = \"gpt2ja-finetune-small\"\n",
    ") -> None:\n",
    "    \n",
    "    # Encode a dataset\n",
    "    subprocess.run(\n",
    "        f\"python gpt2-japanese/encode_bpe.py --src_dir {src_dir} --dst_file {dst_file}\",\n",
    "        shell=True,\n",
    "    )\n",
    "    \n",
    "    # Fine-Tune\n",
    "    subprocess.run(\n",
    "        f\"python gpt2-japanese/run_finetune.py \\\n",
    "            --base_model gpt2ja-small \\\n",
    "            --dataset {dst_file}.npz \\\n",
    "            --run_name {run_name}\",\n",
    "        shell=True,\n",
    "    )\n",
    "    \n",
    "    # Remove interim files\n",
    "    subprocess.run(f\"rm {dst_file}.npz\", shell=True)\n",
    "    subprocess.run(\"for i in `seq 0 7`; do rm tmp$i.pkl; done\", shell=True)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(\n",
    "    model: str = \"checkpoints/gpt2ja-finetune-small\",\n",
    "    num_generate: int = 1,\n",
    "    temperature: float = 1.0,\n",
    "    min_length: int = 120,\n",
    "    max_length: int = 130,\n",
    "    output_file: str = \"dist/dist.txt\",\n",
    "    context: str = \"<|endoftext|>\",\n",
    ") -> str: \n",
    "    \n",
    "    while True:\n",
    "        generated = subprocess.run(\n",
    "            f\"TF_CPP_MIN_LOG_LEVEL=3 \\\n",
    "                python gpt2-japanese/gpt2-generate.py \\\n",
    "                --model {model} \\\n",
    "                --num_generate {num_generate} \\\n",
    "                --temperature {temperature} \\\n",
    "                --min_length {min_length} \\\n",
    "                --max_length {max_length} \\\n",
    "                --output_file {output_file} \\\n",
    "                --context={context}\",\n",
    "            shell=True,\n",
    "            capture_output=True,\n",
    "        ).stdout.decode()\n",
    "        \n",
    "        if not bool(re.search(\"|\".join(NG_WORDS), generated)):\n",
    "            break\n",
    "        \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_tweet(\n",
    "    client: tweepy.Client,\n",
    "    text: str,\n",
    "    score: str,\n",
    "    model: str,\n",
    ") -> None:\n",
    "    json = {}\n",
    "    \n",
    "    poll_or_not = random.randint(0, 100)\n",
    "    if poll_or_not >= 90:\n",
    "        options = []\n",
    "        for _ in range(3):\n",
    "            options.append(\n",
    "                generate(\n",
    "                    model=model, \n",
    "                    context=text,\n",
    "                    num_generate=1, \n",
    "                    output_file=\"dist/dist.txt\", \n",
    "                    min_length=5, \n",
    "                    max_length=24,\n",
    "                )\n",
    "            )\n",
    "        json[\"poll\"] = {\"options\": options, \"duration_minutes\": 30}\n",
    "        \n",
    "    json[\"text\"] = text + f\"\\n score: {score}\"\n",
    "    \n",
    "    return client._make_request(\"POST\", \"/2/tweets\", json=json, user_auth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_tweets(\n",
    "    auth_info: AuthenticationInfo,\n",
    "    model: str | None = None,\n",
    ") -> None:\n",
    "\n",
    "    client = tweepy.Client(\n",
    "        consumer_key=auth_info.api_key,\n",
    "        consumer_secret=auth_info.api_secret_key,\n",
    "        access_token=auth_info.access_token,\n",
    "        access_token_secret=auth_info.access_token_secret,\n",
    "    )\n",
    "    \n",
    "    if model is None:\n",
    "        # If model is not specified, use the oldest one\n",
    "        try:\n",
    "            model = glob.glob(\"./checkpoints/*small\")[0]\n",
    "\n",
    "        # If a fine-tuned GPT-2-ja-small does not exist, make it\n",
    "        except IndexError:\n",
    "            today = datetime.strftime(datetime.today(), '%Y-%m-%d')\n",
    "            finetune(\n",
    "                dst_file=f\"{today}-finetune\",\n",
    "                run_name=f\"gpt2ja-{today}-finetune-small\",\n",
    "            )\n",
    "    else:\n",
    "        if not os.path.exists(f\"./checkpoints/{model}\"):\n",
    "            finetune(\n",
    "                dst_file=f\"{model}-finetune\",\n",
    "                run_name=model,\n",
    "            )\n",
    "\n",
    "        model = f\"./checkpoints/{model}\"\n",
    "     \n",
    "    while True:    \n",
    "        generated_text = generate(\n",
    "            model=model,\n",
    "            context=\"\",\n",
    "            num_generate=1,\n",
    "            output_file=\"dist/dist.txt\",\n",
    "        )\n",
    "        \n",
    "        score = (\n",
    "            subprocess.run(\n",
    "                f\"python gpt2-japanese/gpt2-score.py \\\n",
    "                    dist/dist.txt \\\n",
    "                    --model {model} \\\n",
    "                    --exclude-end\",\n",
    "                shell=True,\n",
    "                capture_output=True,\n",
    "            )\n",
    "            .stdout\n",
    "            .decode()\n",
    "            .split(\"\\t\")[-1]\n",
    "            .strip()\n",
    "        )\n",
    "        \n",
    "        if float(score) > -150:\n",
    "            break\n",
    "\n",
    "    post_tweet(client, text=generated_text, score=score, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_info = AuthenticationInfo(\n",
    "    api_key=os.getenv(\"API_KEY\"),\n",
    "    api_secret_key=os.getenv(\"API_SECRET_KEY\"),\n",
    "    access_token=os.getenv(\"ACCESS_TOKEN\"),\n",
    "    access_token_secret=os.getenv(\"ACCESS_TOKEN_SECRET\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mセル15 を /text-generation/create_tweet.ipynb\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f61646d6972696e675f7661726168616d6968697261222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6963755f677075227d7d/text-generation/create_tweet.ipynb#ch0000014vscode-remote?line=0'>1</a>\u001b[0m create_custom_tweets(auth_info\u001b[39m=\u001b[39;49mauth_info, model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt2ja-2022-07-19-finetune-small\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mセル15 を /text-generation/create_tweet.ipynb\u001b[0m in \u001b[0;36mcreate_custom_tweets\u001b[0;34m(auth_info, model)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f61646d6972696e675f7661726168616d6968697261222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6963755f677075227d7d/text-generation/create_tweet.ipynb#ch0000014vscode-remote?line=34'>35</a>\u001b[0m     generated_text \u001b[39m=\u001b[39m generate(\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f61646d6972696e675f7661726168616d6968697261222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6963755f677075227d7d/text-generation/create_tweet.ipynb#ch0000014vscode-remote?line=35'>36</a>\u001b[0m         model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f61646d6972696e675f7661726168616d6968697261222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6963755f677075227d7d/text-generation/create_tweet.ipynb#ch0000014vscode-remote?line=36'>37</a>\u001b[0m         context\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f61646d6972696e675f7661726168616d6968697261222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6963755f677075227d7d/text-generation/create_tweet.ipynb#ch0000014vscode-remote?line=37'>38</a>\u001b[0m         num_generate\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f61646d6972696e675f7661726168616d6968697261222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6963755f677075227d7d/text-generation/create_tweet.ipynb#ch0000014vscode-remote?line=38'>39</a>\u001b[0m         output_file\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdist/dist.txt\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f61646d6972696e675f7661726168616d6968697261222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6963755f677075227d7d/text-generation/create_tweet.ipynb#ch0000014vscode-remote?line=39'>40</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f61646d6972696e675f7661726168616d6968697261222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6963755f677075227d7d/text-generation/create_tweet.ipynb#ch0000014vscode-remote?line=41'>42</a>\u001b[0m     score \u001b[39m=\u001b[39m (\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f61646d6972696e675f7661726168616d6968697261222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6963755f677075227d7d/text-generation/create_tweet.ipynb#ch0000014vscode-remote?line=42'>43</a>\u001b[0m         subprocess\u001b[39m.\u001b[39mrun(\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f61646d6972696e675f7661726168616d6968697261222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6963755f677075227d7d/text-generation/create_tweet.ipynb#ch0000014vscode-remote?line=43'>44</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpython gpt2-japanese/gpt2-score.py \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f61646d6972696e675f7661726168616d6968697261222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6963755f677075227d7d/text-generation/create_tweet.ipynb#ch0000014vscode-remote?line=53'>54</a>\u001b[0m         \u001b[39m.\u001b[39mstrip()\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f61646d6972696e675f7661726168616d6968697261222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6963755f677075227d7d/text-generation/create_tweet.ipynb#ch0000014vscode-remote?line=54'>55</a>\u001b[0m     )\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f61646d6972696e675f7661726168616d6968697261222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6963755f677075227d7d/text-generation/create_tweet.ipynb#ch0000014vscode-remote?line=56'>57</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mfloat\u001b[39;49m(score) \u001b[39m>\u001b[39m \u001b[39m-\u001b[39m\u001b[39m150\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f61646d6972696e675f7661726168616d6968697261222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6963755f677075227d7d/text-generation/create_tweet.ipynb#ch0000014vscode-remote?line=57'>58</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f61646d6972696e675f7661726168616d6968697261222c2273657474696e6773223a7b22686f7374223a227373683a2f2f6963755f677075227d7d/text-generation/create_tweet.ipynb#ch0000014vscode-remote?line=59'>60</a>\u001b[0m post_tweet(client, text\u001b[39m=\u001b[39mgenerated_text, score\u001b[39m=\u001b[39mscore, model\u001b[39m=\u001b[39mmodel)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "create_custom_tweets(auth_info=auth_info, model=\"gpt2ja-2022-07-19-finetune-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('textgen')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80cfaf54ddc48834aebaa66aa95b4002d516e0c3f63b9bd458051d5ed5e0fa4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
